{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Improving the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will improve the search index and query functions from the previous assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data and Defining Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is copied from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, bz2, re\n",
    "from collections import namedtuple, defaultdict, Counter\n",
    "from IPython.display import display, HTML\n",
    "from math import log10, sqrt\n",
    "\n",
    "Summaries_file = 'data/influenza_Summaries.pkl.bz2'\n",
    "Abstracts_file = 'data/influenza_Abstracts.pkl.bz2'\n",
    "\n",
    "Summaries = pickle.load( bz2.BZ2File( Summaries_file, 'rb' ) )\n",
    "Abstracts = pickle.load( bz2.BZ2File( Abstracts_file, 'rb' ) )\n",
    "\n",
    "paper = namedtuple( 'paper', ['title', 'authors', 'year', 'doi'] )\n",
    "for (id, paper_info) in Summaries.items():\n",
    "    Summaries[id] = paper( *paper_info )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Function that tokenizes a string in a rather naive way. Can be extended later.\n",
    "    \"\"\"\n",
    "    return text.split(' ')\n",
    "\n",
    "def preprocess(tokens):\n",
    "    \"\"\"\n",
    "    Perform linguistic preprocessing on a list of tokens. Can be extended later.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        result.append(token.lower())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary( id, show_abstract=False, show_id=True, extra_text='' ):\n",
    "    \"\"\"\n",
    "    Function for printing a paper's summary through IPython's Rich Display System.\n",
    "    Trims long author lists, and adds a link to the paper's DOI (when available).\n",
    "    \"\"\"\n",
    "    s = Summaries[id]\n",
    "    lines = []\n",
    "    title = s.title\n",
    "    if s.doi != '':\n",
    "        title = '<a href=http://dx.doi.org/{:s}>{:s}</a>'.format(s.doi, title)\n",
    "    title = '<strong>' + title + '</strong>'\n",
    "    lines.append(title)\n",
    "    authors = ', '.join( s.authors[:20] ) + ('' if len(s.authors) <= 20 else ', ...')\n",
    "    lines.append(str(s.year) + '. ' + authors)\n",
    "    if (show_abstract):\n",
    "        lines.append('<small><strong>Abstract:</strong> <em>{:s}</em></small>'.format(Abstracts[id]))\n",
    "    if (show_id):\n",
    "        lines.append('[ID: {:d}]'.format(id))\n",
    "    if (extra_text != ''):\n",
    "         lines.append(extra_text)\n",
    "    display( HTML('<br>'.join(lines)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = defaultdict(set)\n",
    "\n",
    "for (id, abstract) in Abstracts.items():\n",
    "    for term in preprocess(tokenize(abstract)):\n",
    "        inverted_index[term].add(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see from the results of the last assignment, our simple index doesn't handle punctuation and the difference between singular and plural versions of the same word very well. We won't go much into the details of tokenization and linguistic analysis here, because we also want to focus on scoring and ranking below. Therefore, we are using an existing library for tokenizatoin and stemming, namely the NLTK package. The following line will install NLTK if necessary (or you have to follow [these instructions](http://www.nltk.org/install.html) if that doesn't work):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/Mylene/anaconda3/lib/python3.6/site-packages (3.3)\r\n",
      "Requirement already satisfied: six in /Users/Mylene/anaconda3/lib/python3.6/site-packages (from nltk) (1.11.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install --user nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Mylene/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "INPUT TEXT:\n",
      "  Good muffins cost $3.88\n",
      "in New York.  Please buy me two of them.\n",
      "\n",
      "Thanks.\n",
      "TOKENIZE:  ['Good', 'muffins', 'cost', '$3.88\\nin', 'New', 'York.', '', 'Please', 'buy', 'me', 'two', 'of', 'them.\\n\\nThanks.']\n",
      "WORD TOKENIZE:  ['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.', 'Please', 'buy', 'me', 'two', 'of', 'them', '.', 'Thanks', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "stemmer = EnglishStemmer()\n",
    "\n",
    "s = '''Good muffins cost $3.88\\nin New York.  Please buy me two of them.\\n\\nThanks.'''\n",
    "\n",
    "print('INPUT TEXT:\\n ', s)\n",
    "\n",
    "print('TOKENIZE: ', tokenize(s))\n",
    "print('WORD TOKENIZE: ', word_tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process\n"
     ]
    }
   ],
   "source": [
    "print(stemmer.stem(\"processes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important method to improve our search results is to rank them, which can be done by calculating a score for each document based on the matching terms from the query. One such scoring method is *tf-idf*, which comes with several variants, as explained in the lecture slides.\n",
    "\n",
    "In order to quickly calculate the scores for a term/document combination, we'll need quick access to a couple of things:\n",
    "\n",
    "- tf(t,d): How often does a term occur in a document\n",
    "- df(t): In how many documents does a term occur\n",
    "- num_documents: The number of documents in our index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_matrix = defaultdict(Counter)\n",
    "\n",
    "for (doc_id, abstract) in Abstracts.items():\n",
    "    tokens = preprocess(tokenize(abstract))\n",
    "    tf_matrix[doc_id] = Counter(tokens)\n",
    "\n",
    "def tf(t,d):\n",
    "    return float(tf_matrix[d][t])\n",
    "\n",
    "def df(t):\n",
    "    return float(len(inverted_index[t]))\n",
    "\n",
    "num_documents = float(len(Abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test these functions with some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n",
      "11.0\n",
      "87602.0\n"
     ]
    }
   ],
   "source": [
    "print(tf('madagascar', 12458917))\n",
    "print(df('madagascar'))\n",
    "print(num_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these helper functions, we can now easily calculate the _tf-idf_ weights of a term in a document by implementing the weighting formula from the slides, which you will do in the assignments below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your name:** M.A.K. Martodihardjo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Implement in the code block below the `smarter_tokenize` function using NLTK's function for tokenization, and the `smarter_preprocess` function to perform stemming in addition to case normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'buy', 'mani', 'book', ',', 'some', 'about', 'i.r.', ',', 'for', 'less', 'than', '$', '1.50', '!']\n"
     ]
    }
   ],
   "source": [
    "# Smarter linguistic processing\n",
    "\n",
    "def smarter_tokenize(text):\n",
    "    \"\"\"\n",
    "    Function that tokenizes a string using the NLTK's function for tokenization.\n",
    "    \"\"\"\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def smarter_preprocess(tokens):\n",
    "    \"\"\"\n",
    "    Perform linguistic preprocessing on a list of tokens such as stemming in addition to case normalization.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    [ result.append(stemmer.stem(token)) for token in tokens ]\n",
    "    return result\n",
    "\n",
    "# To test it:\n",
    "print(smarter_preprocess(smarter_tokenize(\"He buys many books, some about I.R., for less than $1.50!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can make a smarter index based on these functions. For practical purposes, the code below generates the smarter index on a subset of the data, as generating an index with stemming on the entire set would take too much time. (You don't need to change or add anything in the code block below. Just leave it as it is.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, we create our smarter index (based on a subset of the documents for demonstration purposes)\n",
    "smarter_index = defaultdict(set)\n",
    "\n",
    "# Here we define the subset (somewhat arbitrary):\n",
    "subset_of_ids = set(key for key in Abstracts.keys() if 28900000 <= key < 29000000)\n",
    "subset_of_abstracts = ((key, Abstracts[key]) for key in subset_of_ids)\n",
    "\n",
    "# Building our smarter index:\n",
    "for (id, abstract) in subset_of_abstracts:\n",
    "    for term in smarter_preprocess(smarter_tokenize(abstract)):\n",
    "        smarter_index[term].add(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the `smarter_and_query` function, based on the two functions `smarter_tokenize` and `smarter_preprocess` you defined above and accessing our new index `smarter_index`. You can start from the code for `and_query` from the last assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smarter and_query based on the smarter tokenize and preprocess functions\n",
    "\n",
    "def smarter_query_inverted_index(string):\n",
    "    \"\"\"\n",
    "    Function that returns a dictionary with the query term as keys\n",
    "    and the set of document ID as a value using the smarter functions.\n",
    "    \"\"\"\n",
    "    dict_inverted_index = defaultdict(set) \n",
    "    [ dict_inverted_index[term].add(index) for term in smarter_preprocess(smarter_tokenize(string)) for index in smarter_index[term] ] \n",
    "    return dict_inverted_index\n",
    "\n",
    "def smarter_and_query(query_string):\n",
    "    \"\"\"\n",
    "    Function that returns matching documents ID's containing all the words in the query.\n",
    "    \"\"\"\n",
    "    dict_index = smarter_query_inverted_index(query_string)\n",
    "    result = {}\n",
    "    if len(dict_index) > 0:\n",
    "        first_term = list(dict_index.keys())[0]\n",
    "        result     = dict_index[first_term]\n",
    "        for term in dict_index:\n",
    "            result = result.intersection(dict_index[term])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Run the queries \"therapeutic protections antibodies\" and \"investigate de novo protein design\" with the new `smarter_and_query` function from task 1. Do they return paper *28953867* (this is our exemplary paper from the last assignment)? For each of the two example queries, what do our new smarter functions specifically contribute to the result (as compared to our previous naive implementations for tokenization and preprocessing)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The smarter_and_query('therapeutic protections antibodies') function\n",
      "- Contains paper 28953867: True\n",
      "- Number of hints: 2\n",
      "\n",
      "The smarter_and_query('investigate de novo protein design') function\n",
      "- Contains paper 28953867: True\n",
      "- Number of hints: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"The smarter_and_query('therapeutic protections antibodies') function\")\n",
    "print(\"- Contains paper 28953867:\",\n",
    "      28953867 in smarter_and_query(\"therapeutic protections antibodies\"))\n",
    "print(\"- Number of hints:\",\n",
    "      len(smarter_and_query(\"therapeutic protections antibodies\")))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"The smarter_and_query('investigate de novo protein design') function\")\n",
    "print(\"- Contains paper 28953867:\",\n",
    "      28953867 in smarter_and_query(\"investigate de novo protein design\"))\n",
    "print(\"- Number of hints:\",\n",
    "      len(smarter_and_query(\"investigate de novo protein design\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Our new smarter functions specifically are helpful in cases where the query string contains the plural form where the abstract contains the single form (or the other way around) or where the text contains commas etcetera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "Now we move to a different subject and use our old index again. That is, we **don't** use the smarter functions defined above for tasks 3 to 5!\n",
    "\n",
    "Create a function `tfidf(t,d)` that returns the tf-idf score of term `t` in document `d` by using `tf(t,d)`, `df(t)` and `num_documents` as defined above. To do this, first implement a function `idf(t)` to calculate the inverse document frequency, and then use this function to calculate the full tf-idf. The tf-idf formula can be found on the lecture slides. Use tf-idf with plain (non-logarithmic) term frequency, as applied by scoring variant `ntn`. Test your function with the examples shown below. You can use the `log10(n)` function to calculate the base 10 logarithm.\n",
    "\n",
    "Again, use our old (non-smart) index for this task and the tasks below, and **not** the functions defined in tasks 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9882715120146983\n",
      "1.3759586905709682\n",
      "0.5709737348367643\n"
     ]
    }
   ],
   "source": [
    "def idf(t):\n",
    "    \"\"\"\n",
    "    Function which calculates the inverse document frequency (idf).\n",
    "    \"\"\"\n",
    "    return log10(num_documents/max(1,df(t)))\n",
    "\n",
    "def tfidf(t,d):\n",
    "    \"\"\"\n",
    "    Function which gives the tf-idf score of a term.\n",
    "    \"\"\"\n",
    "    return tf(t,d) * idf(t)\n",
    "\n",
    "print(tfidf('botulinum', 28953867))\n",
    "print(tfidf('protection', 28953867))\n",
    "print(tfidf('with', 28953867))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Create a function `query_ntn(query_string)`, which accepts as input a single query string of one or more words, and returns or prints a list of (up to) 10 best matching documents, along with their score. Use _tf-idf_ to calculate document scores based on the query, applying variant `ntn`, as above (see the formula for the `ntn` version of scoring on the lecture slides). Use an auxiliary function `score_ntn` to calculate the score. The results should be shown in descending order by score.\n",
    "\n",
    "You can start by copying your `or_query` function from assignment 2, then expand that to rank the results, making use of the `tfidf(t,d)` function you created above.\n",
    "\n",
    "Demonstrate your function by giving it the exemplary query string \"adverse effects of influenza vaccination\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(22.345895627761816, 16548114),\n",
       " (19.796925845349847, 22399172),\n",
       " (19.582531918161077, 29058218),\n",
       " (19.180087421268432, 27381724),\n",
       " (18.803238995205064, 23209624),\n",
       " (18.775242000599004, 26319740),\n",
       " (18.48975089157836, 17957995),\n",
       " (18.16844082113355, 29514719),\n",
       " (18.141993301512095, 15799679),\n",
       " (17.830243819525293, 28562111)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query_inverted_index(string):\n",
    "    \"\"\"\n",
    "    Function that returns a dictionary with the query term as keys and the set of document ID as a value.\n",
    "    \"\"\"\n",
    "    dict_inverted_index = defaultdict(set) \n",
    "    [ dict_inverted_index[term].add(index) for term in preprocess(tokenize(string)) for index in inverted_index[term] ] \n",
    "    return dict_inverted_index\n",
    "\n",
    "def or_query(query_string):\n",
    "    \"\"\"\n",
    "    Function that returns matching documents ID's containing one of the words in the query.\n",
    "    \"\"\"\n",
    "    dict_index = query_inverted_index(query_string)\n",
    "    result = {}\n",
    "    if len(dict_index) > 0:\n",
    "        first_term = list(dict_index.keys())[0]\n",
    "        result     = dict_index[first_term]\n",
    "        for term in dict_index:\n",
    "            result = result.union(dict_index[term])\n",
    "    return result\n",
    "\n",
    "def score_ntn(query_words, doc_id):\n",
    "    \"\"\"\n",
    "    Function calculates the tf-idf score, applying the variant ntn.\n",
    "    \"\"\"\n",
    "    final_score = 0\n",
    "    for term in query_words:\n",
    "        final_score += tfidf(term,doc_id)\n",
    "    return final_score\n",
    "\n",
    "def query_ntn(query_string):\n",
    "    \"\"\"\n",
    "    Function returns a list of (up to) 10 best matching documents in descending order,\n",
    "    along with their final ntn score.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for index in or_query(query_string):\n",
    "        score = score_ntn(preprocess(tokenize(query_string)),index)\n",
    "        result[score] = index\n",
    "    return sorted([ (score, doc_id) for score, doc_id in result.items() ], reverse=True)[:10]\n",
    "\n",
    "# Example query:\n",
    "query_ntn(\"adverse effects of influenza vaccination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "In this last task, you should create a second version of the query function from Task 4, called `query_ntc`. This second version should use, as its name suggests, variant `ntc` instead of `ntn`, and therefore apply the cosine similarity measure, in addition to applying _tf-idf_. For this, consult the formula for variant `nnc` on the lecture slides and adopt it to include the _idf_ metric (that is, add the `t` element of `ntc`). (You can drop the square root of |q| in the formula, as indicated on the slides.)\n",
    "\n",
    "As a first step, we can calculate beforehand the length of all document vectors (because they don't depend on the query) for document vectors consisting of _tf-idf_ values. The code below does just that, assuming that you defined the function `tfidf(t,d)` above (don't change this code block, just run it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_length_values = defaultdict(int)\n",
    "\n",
    "for (doc_id, abstract) in Abstracts.items():\n",
    "    l = 0\n",
    "    for t in tf_matrix[doc_id].keys():\n",
    "        l += tfidf(t,doc_id) ** 2\n",
    "    tfidf_length_values[doc_id] = sqrt(l)\n",
    "\n",
    "def tfidf_length(d):\n",
    "    return tfidf_length_values[d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the length of a document vector by calling `tfidf_length(d)`.\n",
    "\n",
    "Based on this, you can now implement `query_ntc` in the code block below. You should again first define an auxiliary function, called `score_ntc`. You can start by copy-pasting the code from Task 4.\n",
    "\n",
    "To output the results, use the provided `display_summary` function to make the output a bit more like the results page of a search engine. Lastly, demonstrate your `query_ntc` function with the same example query as above: \"adverse effects of influenza vaccination\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_display_summary(indices):\n",
    "    \"\"\"\n",
    "    Function displays the summary of all the given indices.\n",
    "    \"\"\"\n",
    "    [ display_summary(index) for index in indices]\n",
    "    return\n",
    "\n",
    "def score_ntc(query_words, doc_id):\n",
    "    \"\"\"\n",
    "    Function calculates the tf-idf score, applying the variant ntc.\n",
    "    \"\"\"\n",
    "    semi_final_score = 0\n",
    "    for term in query_words:\n",
    "        semi_final_score += tfidf(term,doc_id) * idf(term)\n",
    "    return semi_final_score/tfidf_length(doc_id)\n",
    "\n",
    "def query_ntc(query_string):\n",
    "    \"\"\"\n",
    "    Function returns a list of (up to) 10 best matching documents in descending order,\n",
    "    along with their final ntc score.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for index in or_query(query_string):\n",
    "        score = score_ntc(preprocess(tokenize(query_string)),index)\n",
    "        result[score] = index\n",
    "    return sorted([ (score, doc_id) for score, doc_id in result.items() ], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1001/jamapediatrics.2016.4023>Association Between Pandemic Influenza A(H1N1) Vaccination in Pregnancy and Early Childhood Morbidity in Offspring.</a></strong><br>2017. Hviid A, Svanström H, Mølgaard-Nielsen D, Lambach P<br>[ID: 27893898]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1111/j.1440-1843.2004.00616.x>Adverse effects associated with influenza vaccination in patients with COPD: a randomized controlled study.</a></strong><br>2004. Wongsurakiat P, Maranetra KN, Gulprasutdilog P, Aksornint M, Srilum W, Ruengjam C, Sated W<br>[ID: 15612969]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1002/sim.7392>Estimating population effects of vaccination using large, routinely collected data.</a></strong><br>2018. Halloran ME, Hudgens MG<br>[ID: 28722190]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>Effects of acetaminophen on adverse effects of influenza vaccination in health care workers.</strong><br>1993. Aoki FY, Yassi A, Cheang M, Murdzak C, Hammond GW, Seklà LH, Wright B<br>[ID: 8221426]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>[Adverse events following influenza vaccination: reaction to specific reports and the necessity of a central registration system].</strong><br>2007. Swaan CM, van der Sande MA, Speelman P, Conyn-van Spaendonck MA, Straus SM, Coutinho RA<br>[ID: 17957995]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1002/hec.3379>Learning to Trust Flu Shots: Quasi-Experimental Evidence from the 2009 Swine Flu Pandemic.</a></strong><br>2016. Maurer J, Harris KM<br>[ID: 27381724]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1371/journal.pone.0062983>The safety and immunogenicity of trivalent inactivated influenza vaccination: a study of maternal-cord blood pairs in Taiwan.</a></strong><br>2013. Lin SY, Wu ET, Lin CH, Shyu MK, Lee CN<br>[ID: 23762229]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1002/14651858.CD001269>Vaccines for preventing influenza in healthy adults.</a></strong><br>2000. Demicheli V, Rivetti D, Deeks JJ, Jefferson TO<br>[ID: 10796628]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.12961/aprl.2013.16.1.03>[Adverse effects of seasonal flu vaccine and new influenza A (H1N1) vaccine in health care workers].</a></strong><br>2013. Torruella JI, Soto RG, Valls RC, Lozano JV, Carreras DB, Cunillera AB<br>[ID: 23744018]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong><a href=http://dx.doi.org/10.1093/eurpub/ckp227>Perceived risks of adverse effects and influenza vaccination: a survey of hospital employees.</a></strong><br>2010. Ehrenstein BP, Hanses F, Blaas S, Mandraka F, Audebert F, Salzberger B<br>[ID: 20089677]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example results page of a search engine\n",
    "multiple_display_summary([ doc_id for (score,doc_id) in query_ntc(\"adverse effects of influenza vaccination\") ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7020554394764053, 27893898),\n",
       " (0.651026667478441, 15612969),\n",
       " (0.6413128471414885, 28722190),\n",
       " (0.5980012703141494, 8221426),\n",
       " (0.5692121670006679, 17957995),\n",
       " (0.5677824709710214, 27381724),\n",
       " (0.558559635221878, 23762229),\n",
       " (0.5541267528089895, 10796628),\n",
       " (0.5534587820563276, 23744018),\n",
       " (0.5465316810029489, 20089677)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example query:\n",
    "query_ntc(\"adverse effects of influenza vaccination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the answers to the assignment via Canvas as a modified version of this Notebook file (file with `.ipynb` extension) that includes your code and your answers.\n",
    "\n",
    "Before submitting, restart the kernel and re-run the complete code (**Kernel > Restart & Run All**), and then check whether your assignment code still works as expected.\n",
    "\n",
    "Don't forget to add your name, and remember that the assignments have to be done individually and group submissions are **not allowed**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
